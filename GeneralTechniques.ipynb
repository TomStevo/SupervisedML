{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Techniques\n",
    "This notebook collects some general techniques applicable to all classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import Datasets\n",
    "import Plotting\n",
    "import Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (10, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Distributions, ROC Curves and Overtraining\n",
    "Let's consider again the spiral dataset but with the distributions overlapping more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training and testing datasets for the signal and background\n",
    "sig_train = Datasets.gen_spiral( a=0.2, s=0.0, n=1000, w=0.15 )\n",
    "sig_test  = Datasets.gen_spiral( a=0.2, s=0.0, n=1000, w=0.15 )\n",
    "\n",
    "bkg_train = Datasets.gen_spiral( a=-0.2, s=0.2, n=1000, w=0.15 )\n",
    "bkg_test  = Datasets.gen_spiral( a=-0.2, s=0.2, n=1000, w=0.15 )\n",
    "\n",
    "# Using a BDT\n",
    "ABDT = AdaBoostClassifier(tree.DecisionTreeClassifier(max_depth=3),\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=100)\n",
    "\n",
    "Tools.train_mva(ABDT,sig_train,bkg_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decision boundary and points for the testing data\n",
    "Tools.evaluate_mva(ABDT,sig_test,bkg_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_output(clf,sig,bkg):\n",
    "\n",
    "    n_bins = 40\n",
    "    \n",
    "    sig_output = clf.decision_function(sig.values)\n",
    "    bkg_output = clf.decision_function(bkg.values)\n",
    "    \n",
    "    d_min = min(sig_output.min(),bkg_output.min())\n",
    "    d_max = max(sig_output.max(),bkg_output.max())\n",
    "    \n",
    "    plt.hist(bkg_output,bins=n_bins,range=(d_min,d_max), color='tab:orange', label='bkg train',alpha=0.6, density=True)\n",
    "    plt.hist(sig_output,bins=n_bins,range=(d_min,d_max), color='tab:blue', label='sig train', alpha=0.6, density=True)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_output(ABDT,sig_test,bkg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_roc(clf,sig,bkg):\n",
    "    X = np.concatenate( [sig.values,bkg.values] )\n",
    "    y = np.concatenate( [np.ones(len(sig.index)),np.zeros(len(bkg.index))] )\n",
    "\n",
    "    y_score = clf.decision_function(X)\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y.ravel(), y_score.ravel())\n",
    "\n",
    "    roc_auc = auc(fpr,tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(tpr,1-fpr,color='tab:orange', lw=2, label='ROC Curve (area = %0.2f)'%roc_auc)\n",
    "    #plt.plot([1,0],[1,0], color='tab:blue', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0,1.0])\n",
    "    plt.ylim([0.0,1.05])\n",
    "    plt.xlabel('Sig Eff')\n",
    "    plt.ylabel('1 - Bkg Eff')\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_auc = calc_roc(ABDT,sig_test,bkg_test)\n",
    "print(\"Test AUC: \",test_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identifying Overtraining\n",
    "One way to potentially identify overtraining is to consider the MVA output distributions for the training and testing samples. Ideally these will be similar such that the output of the MVA for the training dataset is similar to the output of the MVA for the testing training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_compare_outputs(clf,sig_train,bkg_train,sig_test,bkg_test):\n",
    "\n",
    "    n_bins = 40\n",
    "    \n",
    "    sig_train_output = clf.decision_function(sig_train.values)\n",
    "    bkg_train_output = clf.decision_function(bkg_train.values)\n",
    "\n",
    "    sig_test_output = clf.decision_function(sig_test.values)\n",
    "    bkg_test_output = clf.decision_function(bkg_test.values)\n",
    "    \n",
    "    d_min = min(sig_train_output.min(),bkg_train_output.min())\n",
    "    d_max = max(sig_train_output.max(),bkg_train_output.max())\n",
    "    \n",
    "    sig_tr,bins,_ = plt.hist(bkg_train_output,bins=n_bins,range=(d_min,d_max), color='tab:orange', label='bkg train',alpha=0.6, density=True)\n",
    "    plt.hist(sig_train_output,bins=n_bins,range=(d_min,d_max), color='tab:blue', label='sig train', alpha=0.6, density=True)\n",
    "\n",
    "    bin_centers = (bins[:-1]+bins[1:])/2\n",
    "    sig_te,_ = np.histogram(sig_test_output,bins=bins,density=True)\n",
    "    bkg_te,_ = np.histogram(bkg_test_output,bins=bins,density=True)\n",
    "\n",
    "    plt.plot(bin_centers,bkg_te, 'o', c='tab:orange', label='bkg test', alpha=0.9, markeredgecolor='k')\n",
    "    plt.plot(bin_centers,sig_te, 'o', c='tab:blue', label='sig test', alpha=0.9, markeredgecolor='k')\n",
    "\n",
    "    print(ks_2samp(sig_tr,sig_te))\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kolmogorov-Smirnov (KS) Test provides a test statistic to evaluate whether the two distributions (trainging and testing) are from the same underlying distribution.\n",
    "You can consider the __p-value__ and compare it to a level of significance $\\boldsymbol{\\alpha}$ (we usually $\\boldsymbol{\\alpha}$__=0.05__ or $\\boldsymbol{\\alpha}$__=0.02__), and then if the __p-value__ is less than $\\boldsymbol{\\alpha}$ it is very likely the two distributions are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_compare_outputs(ABDT,sig_train,bkg_train,sig_test,bkg_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errorVsSize(clf,cv,sig,bkg,njobs,train_sizes=np.linspace(.1, 1.0, 10)):\n",
    "    \n",
    "    X = np.concatenate( [sig.values,bkg.values] )\n",
    "    y = np.concatenate( [np.ones(len(sig.index)),np.zeros(len(bkg.index))] )\n",
    "\n",
    "    X,y = shuffle(X,y)\n",
    "\n",
    "    train_sizes, train_scores, test_scores = learning_curve(clf, X, y, cv=cv, n_jobs=njobs, train_sizes=train_sizes)\n",
    "    \n",
    "    train_errors_mean = np.mean(train_scores, axis=1)\n",
    "    train_errors_std = np.std(train_scores, axis=1)\n",
    "    test_errors_mean = np.mean(test_scores, axis=1)\n",
    "    test_errors_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Training Samples\")\n",
    "    plt.ylabel(\"1-Error\")\n",
    "\n",
    "    plt.grid()\n",
    "    plt.fill_between(train_sizes, train_errors_mean - train_errors_std,\n",
    "                     train_errors_mean + train_errors_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_errors_mean - test_errors_std,\n",
    "                     test_errors_mean + test_errors_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_errors_mean, 'o-', color=\"r\",\n",
    "             label=\"Training Error\")\n",
    "    plt.plot(train_sizes, test_errors_mean, 'o-', color=\"g\",\n",
    "             label=\"Test Error\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = Datasets.gen_spiral( a=0.2, s=0.0, n=1000, w=0.15 )\n",
    "bkg = Datasets.gen_spiral( a=-0.2, s=0.2, n=1000, w=0.15 )\n",
    "\n",
    "ABDT = AdaBoostClassifier(tree.DecisionTreeClassifier(max_depth=3),\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=100)\n",
    "\n",
    "cv = ShuffleSplit(n_splits=20, test_size=0.2, random_state=0)\n",
    "errorVsSize(ABDT,cv,sig,bkg,4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
